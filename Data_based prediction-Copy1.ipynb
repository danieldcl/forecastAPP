{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "import pylab\n",
    "import csv\n",
    "import math\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, SGDRegressor\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import KFold   #For K-fold cross validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-70bd83b66200>:12: SyntaxWarning: name 'my_file_name' is assigned to before global declaration\n",
      "  global my_file_name\n"
     ]
    }
   ],
   "source": [
    "def Load_data_file(filename): \n",
    "    #the data are load in the system\n",
    "    \n",
    "    my_file_size = os.path.getsize(filename)\n",
    "    if my_file_size < 100000000: # 100 MB is considered big data\n",
    "        global my_file_name\n",
    "        my_file_name = filename\n",
    "        with open(filename,'r') as fi:\n",
    "            df = pd.read_csv(fi)\n",
    "            return df\n",
    "    else:\n",
    "        global my_file_name\n",
    "        my_file_name = filename\n",
    "        with open(filename,'r') as fi:\n",
    "            df = pd.read_csv(fi, nrows=100)\n",
    "            return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = Load_data_file('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def Generate_Var(df) : \n",
    "    #the data our system received have different keys used as variables to make the prediction. \n",
    "    #Knowing that not all the variable are not applicable for all the stores, the system generates \n",
    "    #just the applicable variables.\n",
    "    \n",
    "    return list(df.columns)\n",
    "\n",
    "def Pick_Var(variable): \n",
    "    #the user pick the variables he want to use for the prediction.\n",
    "    \n",
    "    global y_feature\n",
    "    global y_feature_index\n",
    "    y_feature = variable\n",
    "    \n",
    "    for i in range(len(df.columns)):\n",
    "        if df.columns[i]== y_feature:\n",
    "            y_feature_index = i\n",
    "    return variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Store',\n",
       " 'DayOfWeek',\n",
       " 'Date',\n",
       " 'Sales',\n",
       " 'Customers',\n",
       " 'Open',\n",
       " 'Promo',\n",
       " 'StateHoliday',\n",
       " 'SchoolHoliday']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Generate_Var(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sales'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pick_Var('Sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sales'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def x_features():\n",
    "    global x_features\n",
    "    x_features = []\n",
    "    for feat in list(df.columns):\n",
    "        if feat!= y_feature:\n",
    "            x_features.append(feat)\n",
    "    return x_features\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Store',\n",
       " 'DayOfWeek',\n",
       " 'Date',\n",
       " 'Customers',\n",
       " 'Open',\n",
       " 'Promo',\n",
       " 'StateHoliday',\n",
       " 'SchoolHoliday']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def Clean_Data(df): \n",
    "    #the  system remove redundancy, normalize, and preprocess the data\n",
    "    \n",
    "    # Convert Categorical values into numerical values\n",
    "    for i in range (len(df.columns)):\n",
    "        if df[df.columns[i]].dtypes == 'object':\n",
    "            df[df.columns[i]] = df[df.columns[i]].astype('category').cat.codes\n",
    "    \n",
    "    # Fill in missing values\n",
    "    for i in range (len(df.columns)):\n",
    "        if df[df.columns[i]].isnull().any().any():\n",
    "            df[df.columns[i]].fillna(df[df.columns[i]].mean(), inplace=True)\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Clean_Data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Generate_Method(): \n",
    "    #different methods are generated based on data(linear regression, \n",
    "    #clustering, classification, etc..)\n",
    "    \n",
    "    my_file_size = os.path.getsize(my_file_name)\n",
    "    \n",
    "    if my_file_size < 100000000:\n",
    "        methods = ['LinearRegression  ', 'DecisionTree  ', 'RandomForest  ', 'XGBoost  ',' SGDClassifier ']\n",
    "        print('     -- Pick an Algorithm to fit your model--')\n",
    "        print('')\n",
    "        print('\\n'.join(methods))\n",
    "        print('')       \n",
    "    else:\n",
    "        methods = ['SGDClassifier']\n",
    "        print('     -- Pick an Algorithm to fit your model--')\n",
    "        print('')\n",
    "        print('\\n'.join(methods))\n",
    "        print('')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     -- Pick an Algorithm to fit your model--\n",
      "\n",
      "LinearRegression  \n",
      "DecisionTree  \n",
      "RandomForest  \n",
      "XGBoost  \n",
      " SGDClassifier \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Generate_Method()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Generate_Prediction(model): \n",
    "    #the system generate the prediction result\n",
    "    \n",
    "    model= model.lower()\n",
    "    if model== 'xgboost':\n",
    "        return xgboost_model()\n",
    "    \n",
    "    elif model== 'randomforest':\n",
    "        model = RandomForestClassifier(n_estimators=100)\n",
    "        predictor_var = x_features\n",
    "        output_var = y_feature\n",
    "        return classification_model(model, df, predictor_var, output_var)\n",
    "    \n",
    "    elif model== 'decisiontree':\n",
    "        model = DecisionTreeClassifier()\n",
    "        predictor_var = x_features\n",
    "        output_var = y_feature\n",
    "        return classification_model(model, df, predictor_var, output_var)\n",
    "    \n",
    "    elif model== 'sgdclassifier':\n",
    "        return my_SGDClassifier()\n",
    "    \n",
    "    elif model== 'linearregression':\n",
    "        model = LogisticRegression()\n",
    "        predictor_var = x_features[1]\n",
    "        output_var = y_feature\n",
    "        return classification_model(model, df, predictor_var, output_var)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classification_model(model, df, predictor_var, output_var):\n",
    "    #Generic function for making a classification model and accessing performance:\n",
    "          \n",
    "    #Fit the model:\n",
    "    model.fit(df[predictor_var],df[output_var])\n",
    "  \n",
    "    #Make predictions on training set:\n",
    "    predictions = model.predict(df[predictor_var])\n",
    "    \n",
    "    #predictions.to_csv('prediction_result.csv')\n",
    "  \n",
    "    #Print accuracy\n",
    "    accuracy = metrics.accuracy_score(predictions,df[output_var])\n",
    "    print (\"Accuracy : %s\" % \"{0:.3%}\".format(accuracy))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = cross_validation.train_test_split(\n",
    "        df, df[output_var], test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "    #Perform k-fold cross-validation with 5 folds\n",
    "    kf = KFold(df.shape[0], n_folds=5)\n",
    "    error = []\n",
    "    for train, test in kf:\n",
    "        # Filter training data\n",
    "        train_predictor_var = (df[predictor_var].iloc[train,:])\n",
    "    \n",
    "        # The target we're using to train the algorithm.\n",
    "        train_target = df[output_var].iloc[train]\n",
    "    \n",
    "        # Training the algorithm using the predictor_var and target.\n",
    "        model.fit(train_predictor_var, train_target)\n",
    "    \n",
    "        #Record error from each cross-validation run\n",
    "        error.append(model.score(df[predictor_var].iloc[test,:], df[output_var].iloc[test]))\n",
    " \n",
    "    print (\"Cross-Validation Score : %s\" % \"{0:.3%}\".format(np.mean(error)))\n",
    "\n",
    "    #Fit the model again so that it can be refered outside the function:\n",
    "    model.fit(df[predictor_var],df[output_var]) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def ToWeight(y):\n",
    "    w = np.zeros(y.shape, dtype=float)\n",
    "    ind = y != 0\n",
    "    w[ind] = 1./(y[ind]**2)\n",
    "    return w\n",
    "\n",
    "def rmspe(yhat, y):\n",
    "    w = ToWeight(y)\n",
    "    rmspe = np.sqrt(np.mean( w * (y - yhat)**2 ))\n",
    "    return rmspe\n",
    "\n",
    "def rmspe_xg(yhat, y):\n",
    "    # y = y.values\n",
    "    y = y.get_label()\n",
    "    y = np.exp(y) - 1\n",
    "    yhat = np.exp(yhat) - 1\n",
    "    w = ToWeight(y)\n",
    "    rmspe = np.sqrt(np.mean(w * (y - yhat)**2))\n",
    "    return \"rmspe\", rmspe\n",
    "\n",
    "def xgboost_model(): \n",
    "    #the system generate the prediction result\n",
    "    \n",
    "    #our system splits the data, and almost  one third are submit to the system as training data. \n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[x_features], df[y_feature],\n",
    "                                                    test_size=0.2, random_state=30)\n",
    "    \n",
    "    data = np.random.rand(5,10) # 5 entities, each contains 10 features\n",
    "    label = np.random.randint(2, size=5) # binary target\n",
    "    dtrain = xgb.DMatrix( data, label=label)\n",
    "    \n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train, y_train)\n",
    "    dtest = xgb.DMatrix(X_test, y_test)\n",
    "    \n",
    "    num_round = 500\n",
    "    evallist = [(dtrain, 'train'), (dtest, 'test')]\n",
    "    \n",
    "    param = {'bst:max_depth':12,\n",
    "         'bst:eta':0.0095,\n",
    "         'subsample':0.8,\n",
    "         'colsample_bytree':0.7,\n",
    "         'silent':1, \n",
    "         'objective':'reg:linear',\n",
    "         'nthread':6,\n",
    "         'seed':42}\n",
    "\n",
    "    plst = param.items()\n",
    "\n",
    "    bst1 = xgb.train(plst, dtrain, num_round, evallist, feval=rmspe_xg, verbose_eval=50, early_stopping_rounds=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-8c184fd6bf43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mGenerate_Prediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Decisiontree'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-53-719706f0fb63>\u001b[0m in \u001b[0;36mGenerate_Prediction\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mpredictor_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0moutput_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_feature\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mclassification_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictor_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_var\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m==\u001b[0m \u001b[1;34m'sgdclassifier'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-54-98aab288f7cd>\u001b[0m in \u001b[0;36mclassification_model\u001b[1;34m(model, df, predictor_var, output_var)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m#Fit the model:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredictor_var\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moutput_var\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m#Make predictions on training set:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dc/anaconda2/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    348\u001b[0m                                            max_leaf_nodes)\n\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msklearn/tree/_tree.pyx\u001b[0m in \u001b[0;36msklearn.tree._tree.DepthFirstTreeBuilder.build (sklearn/tree/_tree.c:4322)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msklearn/tree/_tree.pyx\u001b[0m in \u001b[0;36msklearn.tree._tree.DepthFirstTreeBuilder.build (sklearn/tree/_tree.c:4151)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Generate_Prediction('Decisiontree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until test error hasn't decreased in 100 rounds.\n",
      "[0]\ttrain-rmspe:nan\ttest-rmspe:nan\n",
      "[50]\ttrain-rmspe:nan\ttest-rmspe:nan\n",
      "Stopping. Best iteration:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Generate_Prediction('xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Generate_Prediction('RandomForest')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
